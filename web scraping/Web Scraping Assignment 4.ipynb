{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "78d7bba9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: selenium in c:\\users\\rachn\\anaconda3\\lib\\site-packages (4.17.2)\n",
      "Requirement already satisfied: urllib3[socks]<3,>=1.26 in c:\\users\\rachn\\anaconda3\\lib\\site-packages (from selenium) (1.26.16)\n",
      "Requirement already satisfied: trio~=0.17 in c:\\users\\rachn\\anaconda3\\lib\\site-packages (from selenium) (0.24.0)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in c:\\users\\rachn\\anaconda3\\lib\\site-packages (from selenium) (0.11.1)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in c:\\users\\rachn\\anaconda3\\lib\\site-packages (from selenium) (2023.7.22)\n",
      "Requirement already satisfied: typing_extensions>=4.9.0 in c:\\users\\rachn\\anaconda3\\lib\\site-packages (from selenium) (4.9.0)\n",
      "Requirement already satisfied: attrs>=20.1.0 in c:\\users\\rachn\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (22.1.0)\n",
      "Requirement already satisfied: sortedcontainers in c:\\users\\rachn\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Requirement already satisfied: idna in c:\\users\\rachn\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (3.4)\n",
      "Requirement already satisfied: outcome in c:\\users\\rachn\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.3.0.post0)\n",
      "Requirement already satisfied: sniffio>=1.3.0 in c:\\users\\rachn\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.3.0)\n",
      "Requirement already satisfied: cffi>=1.14 in c:\\users\\rachn\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.15.1)\n",
      "Requirement already satisfied: wsproto>=0.14 in c:\\users\\rachn\\anaconda3\\lib\\site-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
      "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in c:\\users\\rachn\\anaconda3\\lib\\site-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\rachn\\anaconda3\\lib\\site-packages (from cffi>=1.14->trio~=0.17->selenium) (2.21)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in c:\\users\\rachn\\anaconda3\\lib\\site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n"
     ]
    }
   ],
   "source": [
    "#install selenium\n",
    "!pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "dc0569a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import all neccessory libreries of selenium\n",
    "# import debugger\n",
    "import re\n",
    "\n",
    "# selenium\n",
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "\n",
    "# Beautiful soup\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "from selenium.webdriver.common.by import By\n",
    "# add time\n",
    "import time\n",
    "\n",
    "from selenium.common.exceptions import NoSuchElementException, StaleElementReferenceException ,ElementNotInteractableException\n",
    "\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64642c62",
   "metadata": {},
   "source": [
    "1. Scrape  the  \n",
    "details  of  \n",
    "most  viewed  videos  on  \n",
    "YouTube  \n",
    "from  Wikipedia.  \n",
    "Url \n",
    "= https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos You need to find following details:  A) \n",
    "Rank   \n",
    "B) Name   \n",
    "C) Artist   \n",
    "D) Upload date   \n",
    "E) Views   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "81bc8f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# connecting to the webdriver\n",
    "driver=webdriver.Chrome()\n",
    "driver.get(\"http://www.google.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e59669b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get url in web driver first\n",
    "url=\"https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos\"\n",
    "driver.get(url)\n",
    "#the url will open"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1cf08037",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating empty list for scraping the data\n",
    "\n",
    "Rank = []\n",
    "Name = []\n",
    "Artist = []\n",
    "Date = []\n",
    "Views = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "83afb2f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraping Rank of the videos\n",
    "try:\n",
    "    for i in driver.find_elements(By.XPATH,\"//table[@class='wikitable sortable jquery-tablesorter'][1]/tbody/tr/td[1]\"):\n",
    "        Rank.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Rank.append(\"-\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "85bba535",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping Name of the videos\n",
    "try:\n",
    "    for i in driver.find_elements(By.XPATH,\"//table[@class='wikitable sortable jquery-tablesorter'][1]/tbody/tr/td[2]\"):\n",
    "        Name.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Name.append(\"-\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e1bbf483",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping Artist of the videos\n",
    "try:\n",
    "    for i in driver.find_elements(By.XPATH,\"//table[@class='wikitable sortable jquery-tablesorter'][1]/tbody/tr/td[3]\"):\n",
    "        Artist.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Artist.append(\"-\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "53232c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping Upload_Date of the videos\n",
    "try:\n",
    "    for i in driver.find_elements(By.XPATH,\"//table[@class='wikitable sortable jquery-tablesorter'][1]/tbody/tr/td[5]\"):\n",
    "        Date.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Date.append(\"-\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "858ebee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping Views of the videos\n",
    "try:\n",
    "    for i in driver.find_elements(By.XPATH,\"//table[@class='wikitable sortable jquery-tablesorter'][1]/tbody/tr/td[4]\"):\n",
    "        Views.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Views.append(\"-\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d6e2c600",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating DataFrame for scraped data\n",
    "Wiki = pd.DataFrame({})\n",
    "Wiki['Rank'] = Rank\n",
    "Wiki['Name'] = Name\n",
    "Wiki['Artist'] = Artist\n",
    "Wiki['Upload Date'] = Date\n",
    "Wiki['Views (in Billions)'] = Views"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a1b25b66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>Name</th>\n",
       "      <th>Artist</th>\n",
       "      <th>Upload Date</th>\n",
       "      <th>Views (in Billions)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"Baby Shark Dance\"[6]</td>\n",
       "      <td>Pinkfong Baby Shark - Kids'</td>\n",
       "      <td>7,046,700,000</td>\n",
       "      <td>November 2, 2020</td>\n",
       "      <td>June 17, 2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"Despacito\"[9]</td>\n",
       "      <td></td>\n",
       "      <td>2,993,700,000</td>\n",
       "      <td>August 4, 2017</td>\n",
       "      <td>January 12, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"See You Again\"[22]</td>\n",
       "      <td></td>\n",
       "      <td>2,894,000,000</td>\n",
       "      <td>July 10, 2017</td>\n",
       "      <td>April 6, 2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"Gangnam Style\"‚ÅÇ[31]</td>\n",
       "      <td></td>\n",
       "      <td>803,700,000</td>\n",
       "      <td>November 24, 2012</td>\n",
       "      <td>July 15, 2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"Baby\"*[66]</td>\n",
       "      <td></td>\n",
       "      <td>245,400,000</td>\n",
       "      <td>July 16, 2010</td>\n",
       "      <td>February 19, 2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>\"Bad Romance\"[70]</td>\n",
       "      <td></td>\n",
       "      <td>178,400,000</td>\n",
       "      <td>April 14, 2010</td>\n",
       "      <td>November 24, 2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>\"Charlie Bit My Finger\"[74]</td>\n",
       "      <td></td>\n",
       "      <td>128,900,000</td>\n",
       "      <td>October 25, 2009</td>\n",
       "      <td>May 22, 2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>\"Evolution of Dance\"[76]</td>\n",
       "      <td></td>\n",
       "      <td>118,900,000</td>\n",
       "      <td>May 2, 2009</td>\n",
       "      <td>April 6, 2006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>\"Girlfriend\"‚Ä°[78][79]</td>\n",
       "      <td></td>\n",
       "      <td>92,600,000</td>\n",
       "      <td>July 17, 2008</td>\n",
       "      <td>February 27, 2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>\"Evolution of Dance\"[76]</td>\n",
       "      <td></td>\n",
       "      <td>78,400,000</td>\n",
       "      <td>March 15, 2008</td>\n",
       "      <td>April 6, 2006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>\"Music Is My Hot Hot Sex\"‚Ä°[84]</td>\n",
       "      <td></td>\n",
       "      <td>76,600,000</td>\n",
       "      <td>March 1, 2008</td>\n",
       "      <td>April 9, 2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>\"Evolution of Dance\"*[76]</td>\n",
       "      <td></td>\n",
       "      <td>10,600,000</td>\n",
       "      <td>May 19, 2006</td>\n",
       "      <td>April 6, 2006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>\"Pok√©mon Theme Music Video\"‚Ä°[89]</td>\n",
       "      <td></td>\n",
       "      <td>4,300,000</td>\n",
       "      <td>March 12, 2006</td>\n",
       "      <td>November 28, 2005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>\"Myspace ‚Äì The Movie\"‚Ä°[94][95]</td>\n",
       "      <td></td>\n",
       "      <td>2,700,000</td>\n",
       "      <td>February 18, 2006</td>\n",
       "      <td>January 31, 2006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>\"Phony Photo Booth\"‚Ä°[98]</td>\n",
       "      <td></td>\n",
       "      <td>3,400,000</td>\n",
       "      <td>January 21, 2006</td>\n",
       "      <td>December 1, 2005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>\"The Chronic of Narnia Rap\"‚Ä°[104]</td>\n",
       "      <td></td>\n",
       "      <td>2,300,000</td>\n",
       "      <td>January 9, 2006</td>\n",
       "      <td>December 18, 2005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>\"Ronaldinho: Touch of Gold\"‚Ä°*[107]</td>\n",
       "      <td></td>\n",
       "      <td>255,000</td>\n",
       "      <td>October 31, 2005</td>\n",
       "      <td>October 21, 2005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>\"I/O Brush\"‚Ä°*[113]</td>\n",
       "      <td></td>\n",
       "      <td>247,000</td>\n",
       "      <td>October 29, 2005</td>\n",
       "      <td>October 5, 2005</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  Rank                         Name  \\\n",
       "0                \"Baby Shark Dance\"[6]  Pinkfong Baby Shark - Kids'   \n",
       "1                       \"Despacito\"[9]                                \n",
       "2                  \"See You Again\"[22]                                \n",
       "3                 \"Gangnam Style\"‚ÅÇ[31]                                \n",
       "4                          \"Baby\"*[66]                                \n",
       "5                    \"Bad Romance\"[70]                                \n",
       "6          \"Charlie Bit My Finger\"[74]                                \n",
       "7             \"Evolution of Dance\"[76]                                \n",
       "8                \"Girlfriend\"‚Ä°[78][79]                                \n",
       "9             \"Evolution of Dance\"[76]                                \n",
       "10      \"Music Is My Hot Hot Sex\"‚Ä°[84]                                \n",
       "11           \"Evolution of Dance\"*[76]                                \n",
       "12    \"Pok√©mon Theme Music Video\"‚Ä°[89]                                \n",
       "13      \"Myspace ‚Äì The Movie\"‚Ä°[94][95]                                \n",
       "14            \"Phony Photo Booth\"‚Ä°[98]                                \n",
       "15   \"The Chronic of Narnia Rap\"‚Ä°[104]                                \n",
       "16  \"Ronaldinho: Touch of Gold\"‚Ä°*[107]                                \n",
       "17                  \"I/O Brush\"‚Ä°*[113]                                \n",
       "\n",
       "           Artist        Upload Date Views (in Billions)  \n",
       "0   7,046,700,000   November 2, 2020       June 17, 2016  \n",
       "1   2,993,700,000     August 4, 2017    January 12, 2017  \n",
       "2   2,894,000,000      July 10, 2017       April 6, 2015  \n",
       "3     803,700,000  November 24, 2012       July 15, 2012  \n",
       "4     245,400,000      July 16, 2010   February 19, 2010  \n",
       "5     178,400,000     April 14, 2010   November 24, 2009  \n",
       "6     128,900,000   October 25, 2009        May 22, 2007  \n",
       "7     118,900,000        May 2, 2009       April 6, 2006  \n",
       "8      92,600,000      July 17, 2008   February 27, 2007  \n",
       "9      78,400,000     March 15, 2008       April 6, 2006  \n",
       "10     76,600,000      March 1, 2008       April 9, 2007  \n",
       "11     10,600,000       May 19, 2006       April 6, 2006  \n",
       "12      4,300,000     March 12, 2006   November 28, 2005  \n",
       "13      2,700,000  February 18, 2006    January 31, 2006  \n",
       "14      3,400,000   January 21, 2006    December 1, 2005  \n",
       "15      2,300,000    January 9, 2006   December 18, 2005  \n",
       "16        255,000   October 31, 2005    October 21, 2005  \n",
       "17        247,000   October 29, 2005     October 5, 2005  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# removing stray numbers from Name column\n",
    "Wiki.Name = Wiki.Name.apply(lambda x:x[:-4].strip('\"'))\n",
    "Wiki"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44225bfe",
   "metadata": {},
   "source": [
    "2. Scrape the details team India‚Äôs international fixtures from bcci.tv.   \n",
    "Url = https://www.bcci.tv/.   \n",
    "You need to find following details:   \n",
    "A) Series   \n",
    "B) Place   \n",
    "C) Date   \n",
    "D) Time   \n",
    "Note: - From bcci.tv home page you have reach to the international fixture page through code.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "70a38f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# connecting to the webdriver\n",
    "driver=webdriver.Chrome()\n",
    "driver.get(\"http://www.google.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "c94d2ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get url in web driver first\n",
    "url=('https://www.bcci.tv/')\n",
    "driver.get(url)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "00f2b444",
   "metadata": {},
   "outputs": [],
   "source": [
    "btn=driver.find_element(By.XPATH,\"/html/body/header/div[3]/div[2]/ul/div[1]/a[2]\")\n",
    "driver.get(btn.get_attribute(\"href\"))\n",
    "time.sleep(3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "06b71c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating empty lists for scraping the data\n",
    "Match_Title = []\n",
    "Series = []\n",
    "Place = [\n",
    "Date = []\n",
    "Time = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "c8881e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in driver.find_elements(By.XPATH,'//h5[@class=\"match-tournament-name ng-binding\"]'):\n",
    "    Match_Title.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "3a38bcef",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in driver.find_elements(By.XPATH,'//div[@class=\"tags-wrap\"]/span'):\n",
    "    Series.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "beeb2fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in driver.find_elements(By.XPATH,'//span[@class=\"ng-binding ng-scope\"]'):\n",
    "    Place.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "4841ca8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in driver.find_elements(By.XPATH,'//div[@class=\"match-dates ng-binding\"]'):\n",
    "    Date.append(i.text.replace('\\n',' '))\n",
    "    \n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "f3f4a151",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in driver.find_elements(By.XPATH,'//div[@class=\"match-time no-margin ng-binding\"]'):\n",
    "    Time.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "8d40b81f",
   "metadata": {},
   "outputs": [],
   "source": [
    "date=[i.split(' ',3)[:3] for i in Date]\n",
    "date=[' '.join(i) for i in date]\n",
    "Time=[i.split(' ',3)[-1] for i in Date]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "ec5eaa2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MatchTitle</th>\n",
       "      <th>Series</th>\n",
       "      <th>Place</th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>INDIA TOUR OF ZIMBABWE 2024</td>\n",
       "      <td>4th Test</td>\n",
       "      <td>JSCA International Stadium Complex,</td>\n",
       "      <td>23 FEBRUARY, 2024</td>\n",
       "      <td>2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ENGLAND TOUR OF INDIA 2023-24</td>\n",
       "      <td>5th Test</td>\n",
       "      <td>73.0 overs</td>\n",
       "      <td>7 MARCH, 2024</td>\n",
       "      <td>2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ENGLAND TOUR OF INDIA 2023-24</td>\n",
       "      <td>4th Test</td>\n",
       "      <td>Himachal Pradesh Cricket Association Stadium,</td>\n",
       "      <td>6 JULY, 2024</td>\n",
       "      <td>2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>INDIA TOUR OF ZIMBABWE 2024</td>\n",
       "      <td>Men</td>\n",
       "      <td>Harare Sports Club,</td>\n",
       "      <td>7 JULY, 2024</td>\n",
       "      <td>2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>INDIA TOUR OF ZIMBABWE 2024</td>\n",
       "      <td>5th Test</td>\n",
       "      <td>Harare Sports Club,</td>\n",
       "      <td>10 JULY, 2024</td>\n",
       "      <td>2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>INDIA TOUR OF ZIMBABWE 2024</td>\n",
       "      <td>Men</td>\n",
       "      <td>Harare Sports Club,</td>\n",
       "      <td>13 JULY, 2024</td>\n",
       "      <td>2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>INDIA TOUR OF ZIMBABWE 2024</td>\n",
       "      <td>1st T20I</td>\n",
       "      <td>Harare Sports Club,</td>\n",
       "      <td>14 JULY, 2024</td>\n",
       "      <td>2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>INDIA TOUR OF ZIMBABWE 2024</td>\n",
       "      <td>Men</td>\n",
       "      <td>Harare Sports Club,</td>\n",
       "      <td>23 FEBRUARY, 2024</td>\n",
       "      <td>2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ENGLAND TOUR OF INDIA 2023-24</td>\n",
       "      <td>2nd T20I</td>\n",
       "      <td>JSCA International Stadium Complex,</td>\n",
       "      <td>7 MARCH, 2024</td>\n",
       "      <td>2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ENGLAND TOUR OF INDIA 2023-24</td>\n",
       "      <td>Men</td>\n",
       "      <td>73.0 overs</td>\n",
       "      <td>6 JULY, 2024</td>\n",
       "      <td>2024</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      MatchTitle    Series  \\\n",
       "0    INDIA TOUR OF ZIMBABWE 2024  4th Test   \n",
       "1  ENGLAND TOUR OF INDIA 2023-24  5th Test   \n",
       "2  ENGLAND TOUR OF INDIA 2023-24  4th Test   \n",
       "3    INDIA TOUR OF ZIMBABWE 2024       Men   \n",
       "4    INDIA TOUR OF ZIMBABWE 2024  5th Test   \n",
       "5    INDIA TOUR OF ZIMBABWE 2024       Men   \n",
       "6    INDIA TOUR OF ZIMBABWE 2024  1st T20I   \n",
       "7    INDIA TOUR OF ZIMBABWE 2024       Men   \n",
       "8  ENGLAND TOUR OF INDIA 2023-24  2nd T20I   \n",
       "9  ENGLAND TOUR OF INDIA 2023-24       Men   \n",
       "\n",
       "                                           Place               Date  Time  \n",
       "0            JSCA International Stadium Complex,  23 FEBRUARY, 2024  2024  \n",
       "1                                     73.0 overs      7 MARCH, 2024  2024  \n",
       "2  Himachal Pradesh Cricket Association Stadium,       6 JULY, 2024  2024  \n",
       "3                            Harare Sports Club,       7 JULY, 2024  2024  \n",
       "4                            Harare Sports Club,      10 JULY, 2024  2024  \n",
       "5                            Harare Sports Club,      13 JULY, 2024  2024  \n",
       "6                            Harare Sports Club,      14 JULY, 2024  2024  \n",
       "7                            Harare Sports Club,  23 FEBRUARY, 2024  2024  \n",
       "8            JSCA International Stadium Complex,      7 MARCH, 2024  2024  \n",
       "9                                     73.0 overs       6 JULY, 2024  2024  "
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make data frame of fictures from bcci.tv\n",
    "fixtures = pd.DataFrame({})\n",
    "fixtures['MatchTitle']= Match_Title[:10]\n",
    "fixtures['Series'] = Series[:10]\n",
    "fixtures['Place'] = Place[:10]\n",
    "fixtures['Date'] = Date[:10]\n",
    "fixtures['Time'] =Time[:10]\n",
    " \n",
    "fixtures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "79a34f02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bbe23fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f98ee424",
   "metadata": {},
   "source": [
    "3. Scrape the details of State-wise GDP of India from statisticstime.com.   \n",
    "Url = http://statisticstimes.com/   \n",
    "You have to find following details: A) Rank   \n",
    "B) State   \n",
    "C) GSDP(18-19)- at current prices   \n",
    "D) GSDP(19-20)- at current prices   \n",
    "E) Share(18-19)   \n",
    "F) GDP($ billion)   \n",
    "Note: - From statisticstimes home page you have to reach to economy page through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "0e516c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting the webpage of mentioned url\n",
    "url = (\"https://statisticstimes.com/\")\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "eaac82ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clicking on Economy button\n",
    "driver.find_element(By.XPATH,'/html/body/div[2]/div[1]/div[2]/div[2]/button').click()\n",
    "\n",
    "# clicking on India\n",
    "driver.find_element(By.XPATH,'/html/body/div[2]/div[2]/div[2]/div').click()\n",
    "time.sleep(3)\n",
    "\n",
    "# clicking on GDP of Indian Economy\n",
    "GDP = driver.find_element(By.XPATH,'/html/body/div[2]/div[2]/div[2]/ul/li[1]/a').click()\n",
    "time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "e11652f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating empty list\n",
    "Rank = []\n",
    "State = []\n",
    "GSDP1 = []\n",
    "GSDP2 = []\n",
    "Share = []\n",
    "GDP_billion = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "c98ee6f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraping Rank\n",
    "try:\n",
    "    for i in driver.find_elements(By.XPATH,\"//table[@class='display dataTable']/tbody/tr/td[1]\"):\n",
    "        Rank.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Rank.append(\"_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "32e9a657",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraping State\n",
    "try:\n",
    "    for i in driver.find_elements(By.XPATH,\"//table[@class='display dataTable']/tbody/tr/td[2]\"):\n",
    "        State.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    State.append(\"_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "61311207",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraping GSDP at current price (19-20)\n",
    "try:\n",
    "    for i in driver.find_elements(By.XPATH,\"//table[@class='display dataTable']/tbody/tr/td[3]\"):\n",
    "        GSDP1.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    GSDP1.append(\"_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "54fb986c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraping GSDP at current price (18-19)\n",
    "try:\n",
    "    for i in driver.find_elements(By.XPATH,\"//table[@class='display dataTable']/tbody/tr/td[4]\"):\n",
    "        GSDP2.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    GSDP2.append(\"_\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "336796fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraping Share (18-19)\n",
    "try:\n",
    "    for i in driver.find_elements(By.XPATH,\"//table[@class='display dataTable']/tbody/tr/td[5]\"):\n",
    "        Share.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Share.append(\"_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "70cb860f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraping GDP $ billion\n",
    "try:\n",
    "    for i in driver.find_elements(By.XPATH,\"//table[@class='display dataTable']/tbody/tr/td[6]\"):\n",
    "        GDP_billion.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    GDP_billion.append(\"_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "d93e55c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>State</th>\n",
       "      <th>GSDP at current price (19-20)</th>\n",
       "      <th>GSDP at current price (18-19)</th>\n",
       "      <th>Share (18-19)</th>\n",
       "      <th>GDP($ billion)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Maharashtra</td>\n",
       "      <td>-</td>\n",
       "      <td>3,108,022</td>\n",
       "      <td>13.24%</td>\n",
       "      <td>417.163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Tamil Nadu</td>\n",
       "      <td>2,364,514</td>\n",
       "      <td>2,071,286</td>\n",
       "      <td>8.82%</td>\n",
       "      <td>278.011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Uttar Pradesh</td>\n",
       "      <td>2,257,575</td>\n",
       "      <td>1,974,532</td>\n",
       "      <td>8.41%</td>\n",
       "      <td>265.024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Karnataka</td>\n",
       "      <td>2,241,368</td>\n",
       "      <td>1,962,725</td>\n",
       "      <td>8.36%</td>\n",
       "      <td>263.440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Gujarat</td>\n",
       "      <td>-</td>\n",
       "      <td>1,937,066</td>\n",
       "      <td>8.25%</td>\n",
       "      <td>259.996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>29</td>\n",
       "      <td>Arunachal Pradesh</td>\n",
       "      <td>-</td>\n",
       "      <td>31,669</td>\n",
       "      <td>0.16%</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>30</td>\n",
       "      <td>Sikkim</td>\n",
       "      <td>35,670</td>\n",
       "      <td>31,519</td>\n",
       "      <td>0.16%</td>\n",
       "      <td>17,832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>31</td>\n",
       "      <td>Nagaland</td>\n",
       "      <td>-</td>\n",
       "      <td>27,859</td>\n",
       "      <td>0.14%</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>32</td>\n",
       "      <td>Mizoram</td>\n",
       "      <td>-</td>\n",
       "      <td>24,293</td>\n",
       "      <td>0.12%</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>33</td>\n",
       "      <td>Andaman &amp; Nicobar Islands</td>\n",
       "      <td>-</td>\n",
       "      <td>9,209</td>\n",
       "      <td>0.05%</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>66 rows √ó 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rank                      State GSDP at current price (19-20)  \\\n",
       "0     1                Maharashtra                             -   \n",
       "1     2                 Tamil Nadu                     2,364,514   \n",
       "2     3              Uttar Pradesh                     2,257,575   \n",
       "3     4                  Karnataka                     2,241,368   \n",
       "4     5                    Gujarat                             -   \n",
       "..  ...                        ...                           ...   \n",
       "61   29          Arunachal Pradesh                             -   \n",
       "62   30                     Sikkim                        35,670   \n",
       "63   31                   Nagaland                             -   \n",
       "64   32                    Mizoram                             -   \n",
       "65   33  Andaman & Nicobar Islands                             -   \n",
       "\n",
       "   GSDP at current price (18-19) Share (18-19) GDP($ billion)  \n",
       "0                      3,108,022        13.24%        417.163  \n",
       "1                      2,071,286         8.82%        278.011  \n",
       "2                      1,974,532         8.41%        265.024  \n",
       "3                      1,962,725         8.36%        263.440  \n",
       "4                      1,937,066         8.25%        259.996  \n",
       "..                           ...           ...            ...  \n",
       "61                        31,669         0.16%              -  \n",
       "62                        31,519         0.16%         17,832  \n",
       "63                        27,859         0.14%              -  \n",
       "64                        24,293         0.12%              -  \n",
       "65                         9,209         0.05%              -  \n",
       "\n",
       "[66 rows x 6 columns]"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating DataFrame from the scraped data\n",
    "GDP = pd.DataFrame({})\n",
    "GDP['Rank'] = Rank\n",
    "GDP['State'] = State\n",
    "GDP['GSDP at current price (19-20)'] = GSDP1\n",
    "GDP['GSDP at current price (18-19)'] = GSDP2\n",
    "GDP['Share (18-19)'] = Share\n",
    "GDP['GDP($ billion)'] = GDP_billion\n",
    "GDP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "74869ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c99e7d08",
   "metadata": {},
   "source": [
    "4. Scrape the details of trending repositories on Github.com.   \n",
    "Url = https://github.com/   \n",
    "You have to find the following details:   \n",
    "A) Repository title   \n",
    "B) Repository description   \n",
    "C) Contributors count   \n",
    "D) Language used  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "65598bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# connecting to the webdrive\n",
    "driver=webdriver.Chrome()\n",
    "driver.get(\"http://www.google.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "73837603",
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting the webpage of mentioned url\n",
    "url = (\"https://github.com/\")\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "e24e311e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exception Raised:  Message: element not interactable\n",
      "  (Session info: chrome=121.0.6167.185)\n",
      "Stacktrace:\n",
      "\tGetHandleVerifier [0x00007FF685B17012+3522402]\n",
      "\t(No symbol) [0x00007FF685738352]\n",
      "\t(No symbol) [0x00007FF6855E596D]\n",
      "\t(No symbol) [0x00007FF68562D3C6]\n",
      "\t(No symbol) [0x00007FF685621910]\n",
      "\t(No symbol) [0x00007FF68564F05A]\n",
      "\t(No symbol) [0x00007FF68562120A]\n",
      "\t(No symbol) [0x00007FF68564F270]\n",
      "\t(No symbol) [0x00007FF68566BDA3]\n",
      "\t(No symbol) [0x00007FF68564EE03]\n",
      "\t(No symbol) [0x00007FF68561F4D4]\n",
      "\t(No symbol) [0x00007FF6856205F1]\n",
      "\tGetHandleVerifier [0x00007FF685B49B9D+3730157]\n",
      "\tGetHandleVerifier [0x00007FF685B9F02D+4079485]\n",
      "\tGetHandleVerifier [0x00007FF685B975D3+4048163]\n",
      "\tGetHandleVerifier [0x00007FF68586A649+718233]\n",
      "\t(No symbol) [0x00007FF685744A3F]\n",
      "\t(No symbol) [0x00007FF68573FA94]\n",
      "\t(No symbol) [0x00007FF68573FBC2]\n",
      "\t(No symbol) [0x00007FF68572F2E4]\n",
      "\tBaseThreadInitThunk [0x00007FF83161257D+29]\n",
      "\tRtlUserThreadStart [0x00007FF83272AA58+40]\n",
      "\n"
     ]
    },
    {
     "ename": "InvalidArgumentException",
     "evalue": "Message: invalid argument: 'url' must be a string\n  (Session info: chrome=121.0.6167.185)\nStacktrace:\n\tGetHandleVerifier [0x00007FF685B17012+3522402]\n\t(No symbol) [0x00007FF685738352]\n\t(No symbol) [0x00007FF6855E5ABB]\n\t(No symbol) [0x00007FF68566C7EA]\n\t(No symbol) [0x00007FF68564F05A]\n\t(No symbol) [0x00007FF68566BDA3]\n\t(No symbol) [0x00007FF68564EE03]\n\t(No symbol) [0x00007FF68561F4D4]\n\t(No symbol) [0x00007FF6856205F1]\n\tGetHandleVerifier [0x00007FF685B49B9D+3730157]\n\tGetHandleVerifier [0x00007FF685B9F02D+4079485]\n\tGetHandleVerifier [0x00007FF685B975D3+4048163]\n\tGetHandleVerifier [0x00007FF68586A649+718233]\n\t(No symbol) [0x00007FF685744A3F]\n\t(No symbol) [0x00007FF68573FA94]\n\t(No symbol) [0x00007FF68573FBC2]\n\t(No symbol) [0x00007FF68572F2E4]\n\tBaseThreadInitThunk [0x00007FF83161257D+29]\n\tRtlUserThreadStart [0x00007FF83272AA58+40]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentException\u001b[0m                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[263], line 11\u001b[0m\n\u001b[0;32m      9\u001b[0m trend_url \u001b[38;5;241m=\u001b[39m driver\u001b[38;5;241m.\u001b[39mfind_element(By\u001b[38;5;241m.\u001b[39mXPATH,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/html/body/div[1]/div[1]/header/div/div[2]/div/nav/ul/li[1]/button\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     10\u001b[0m urls \u001b[38;5;241m=\u001b[39m trend_url\u001b[38;5;241m.\u001b[39mget_attribute(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhref\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 11\u001b[0m driver\u001b[38;5;241m.\u001b[39mget(urls)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:356\u001b[0m, in \u001b[0;36mWebDriver.get\u001b[1;34m(self, url)\u001b[0m\n\u001b[0;32m    354\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget\u001b[39m(\u001b[38;5;28mself\u001b[39m, url: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    355\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Loads a web page in the current browser session.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 356\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexecute(Command\u001b[38;5;241m.\u001b[39mGET, {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124murl\u001b[39m\u001b[38;5;124m\"\u001b[39m: url})\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:347\u001b[0m, in \u001b[0;36mWebDriver.execute\u001b[1;34m(self, driver_command, params)\u001b[0m\n\u001b[0;32m    345\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_executor\u001b[38;5;241m.\u001b[39mexecute(driver_command, params)\n\u001b[0;32m    346\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response:\n\u001b[1;32m--> 347\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39merror_handler\u001b[38;5;241m.\u001b[39mcheck_response(response)\n\u001b[0;32m    348\u001b[0m     response[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_unwrap_value(response\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    349\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\selenium\\webdriver\\remote\\errorhandler.py:229\u001b[0m, in \u001b[0;36mErrorHandler.check_response\u001b[1;34m(self, response)\u001b[0m\n\u001b[0;32m    227\u001b[0m         alert_text \u001b[38;5;241m=\u001b[39m value[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124malert\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    228\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exception_class(message, screen, stacktrace, alert_text)  \u001b[38;5;66;03m# type: ignore[call-arg]  # mypy is not smart enough here\u001b[39;00m\n\u001b[1;32m--> 229\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exception_class(message, screen, stacktrace)\n",
      "\u001b[1;31mInvalidArgumentException\u001b[0m: Message: invalid argument: 'url' must be a string\n  (Session info: chrome=121.0.6167.185)\nStacktrace:\n\tGetHandleVerifier [0x00007FF685B17012+3522402]\n\t(No symbol) [0x00007FF685738352]\n\t(No symbol) [0x00007FF6855E5ABB]\n\t(No symbol) [0x00007FF68566C7EA]\n\t(No symbol) [0x00007FF68564F05A]\n\t(No symbol) [0x00007FF68566BDA3]\n\t(No symbol) [0x00007FF68564EE03]\n\t(No symbol) [0x00007FF68561F4D4]\n\t(No symbol) [0x00007FF6856205F1]\n\tGetHandleVerifier [0x00007FF685B49B9D+3730157]\n\tGetHandleVerifier [0x00007FF685B9F02D+4079485]\n\tGetHandleVerifier [0x00007FF685B975D3+4048163]\n\tGetHandleVerifier [0x00007FF68586A649+718233]\n\t(No symbol) [0x00007FF685744A3F]\n\t(No symbol) [0x00007FF68573FA94]\n\t(No symbol) [0x00007FF68573FBC2]\n\t(No symbol) [0x00007FF68572F2E4]\n\tBaseThreadInitThunk [0x00007FF83161257D+29]\n\tRtlUserThreadStart [0x00007FF83272AA58+40]\n"
     ]
    }
   ],
   "source": [
    "# getting explore button and clicking on it\n",
    "try:\n",
    "    explore = driver.find_element(By.XPATH,\"/html/body/div[1]/div[1]/header/div/div[2]/div/nav/ul/li[1]/div/div[2]/span\").click()\n",
    "\n",
    "except ElementNotInteractableException as e:\n",
    "    print(\"Exception Raised: \", e)\n",
    "\n",
    "# selecting trending option\n",
    "trend_url = driver.find_element(By.XPATH,\"/html/body/div[1]/div[1]/header/div/div[2]/div/nav/ul/li[1]/button\")\n",
    "urls = trend_url.get_attribute(\"href\")\n",
    "driver.get(urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dad1154",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "829e1b6b",
   "metadata": {},
   "source": [
    "5.Scrape the details of top 100 songs on billiboard.com. Url = https:/www.billboard.com/  You have to find the \n",
    "following details:   \n",
    "A) Song name   \n",
    "B) Artist name   \n",
    "C) Last week rank   \n",
    "D) Peak rank   \n",
    "E) Weeks on board  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "ae8f0f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# connecting to the webdrive\n",
    "driver=webdriver.Chrome()\n",
    "driver.get(\"http://www.google.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "0ca7dacc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting the webpage of mentioned url\n",
    "url = (\"https://www.billboard.com/\")\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "c6cf6723",
   "metadata": {},
   "outputs": [],
   "source": [
    "#serch button click\n",
    "charts_button =driver.find_element(By.XPATH,'/html/body/div[3]/div[9]/div/div/div/ul/li[1]/h3/a')\n",
    "charts_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "10124229",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating empty lists\n",
    "Song_Name = []\n",
    "Artist_Name =[]\n",
    "Last_week_rank = []\n",
    "Peak_rank = []\n",
    "Weeks_on_board = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "b16024ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting urls for top 100 songs\n",
    "urls = driver.find_element(By.XPATH,'//a[@class=\"c-label__link lrv-u-color-brand-primary u-color-black@mobile-max a-font-primary-bold lrv-u-font-size-32 u-whitespace-nowrap@tablet\"]')\n",
    "page_url = urls.get_attribute(\"href\")\n",
    "driver.get(page_url)\n",
    "time.sleep(4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "a0c8610a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraping data of song names\n",
    "for i in driver.find_elements(By.XPATH,'//h3[@class=\"c-title  a-no-trucate a-font-primary-bold-s u-letter-spacing-0021 u-font-size-23@tablet lrv-u-font-size-16 u-line-height-125 u-line-height-normal@mobile-max a-truncate-ellipsis u-max-width-245 u-max-width-230@tablet-only u-letter-spacing-0028@tablet\"]'):\n",
    "    Song_Name.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "4a7b4a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraping data of artist names\n",
    "for i in driver.find_elements(By.XPATH,'//span[@class=\"c-label  a-no-trucate a-font-primary-s lrv-u-font-size-14@mobile-max u-line-height-normal@mobile-max u-letter-spacing-0021 lrv-u-display-block a-truncate-ellipsis-2line u-max-width-330 u-max-width-230@tablet-only u-font-size-20@tablet\"]'):\n",
    "    Artist_Name.append(i.text)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "9d7579c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraping data of last week ranks\n",
    "for i in driver.find_elements(By.XPATH,'//span[@class=\"c-label  a-font-primary-bold-l a-font-primary-m@mobile-max u-font-weight-normal@mobile-max lrv-u-padding-tb-050@mobile-max u-font-size-32@tablet\"]'):\n",
    "    Last_week_rank.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "a52e6f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraping data of peak ranks\n",
    "for i in driver.find_elements(By.XPATH,\"/html/body/div[3]/main/div[2]/div[3]/div/div/div/div[2]/div[2]/ul/li[4]/ul/li[5]/span\"):\n",
    "    Peak_rank.append(i.text)       \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "56c543cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraping data of weeks on board\n",
    "for i in driver.find_elements(By.XPATH,\"/html/body/div[3]/main/div[2]/div[3]/div/div/div/div[2]/div[2]/ul/li[4]/ul/li[6]/span\"):\n",
    "    Weeks_on_board.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "dfc7c221",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Length of values (6) does not match length of index (1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[302], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m billiboard[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mName\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m Song_Name\n\u001b[0;32m      4\u001b[0m billiboard[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mArtist\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m Artist_Name\n\u001b[1;32m----> 5\u001b[0m billiboard[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLast Week Rank\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m Last_week_rank\n\u001b[0;32m      6\u001b[0m billiboard[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPeak Rank\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m Peak_rank\n\u001b[0;32m      7\u001b[0m billiboard[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mWeeks on board\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m Weeks_on_board\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:3950\u001b[0m, in \u001b[0;36mDataFrame.__setitem__\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   3947\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_setitem_array([key], value)\n\u001b[0;32m   3948\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   3949\u001b[0m     \u001b[38;5;66;03m# set column\u001b[39;00m\n\u001b[1;32m-> 3950\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_item(key, value)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:4143\u001b[0m, in \u001b[0;36mDataFrame._set_item\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   4133\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_set_item\u001b[39m(\u001b[38;5;28mself\u001b[39m, key, value) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   4134\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   4135\u001b[0m \u001b[38;5;124;03m    Add series to DataFrame in specified column.\u001b[39;00m\n\u001b[0;32m   4136\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4141\u001b[0m \u001b[38;5;124;03m    ensure homogeneity.\u001b[39;00m\n\u001b[0;32m   4142\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 4143\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sanitize_column(value)\n\u001b[0;32m   4145\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m   4146\u001b[0m         key \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\n\u001b[0;32m   4147\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m value\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   4148\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_extension_array_dtype(value)\n\u001b[0;32m   4149\u001b[0m     ):\n\u001b[0;32m   4150\u001b[0m         \u001b[38;5;66;03m# broadcast across multiple columns if necessary\u001b[39;00m\n\u001b[0;32m   4151\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mis_unique \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns, MultiIndex):\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:4870\u001b[0m, in \u001b[0;36mDataFrame._sanitize_column\u001b[1;34m(self, value)\u001b[0m\n\u001b[0;32m   4867\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _reindex_for_setitem(Series(value), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex)\n\u001b[0;32m   4869\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_list_like(value):\n\u001b[1;32m-> 4870\u001b[0m     com\u001b[38;5;241m.\u001b[39mrequire_length_match(value, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex)\n\u001b[0;32m   4871\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m sanitize_array(value, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, allow_2d\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\common.py:576\u001b[0m, in \u001b[0;36mrequire_length_match\u001b[1;34m(data, index)\u001b[0m\n\u001b[0;32m    572\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    573\u001b[0m \u001b[38;5;124;03mCheck the length of data matches the length of the index.\u001b[39;00m\n\u001b[0;32m    574\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    575\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(data) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(index):\n\u001b[1;32m--> 576\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    577\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLength of values \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    578\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(data)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    579\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdoes not match length of index \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    580\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(index)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    581\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Length of values (6) does not match length of index (1)"
     ]
    }
   ],
   "source": [
    "# creating dataframe for scraped data\n",
    "billiboard = pd.DataFrame({})\n",
    "billiboard['Name'] = Song_Name\n",
    "billiboard['Artist'] = Artist_Name\n",
    "billiboard['Last Week Rank'] = Last_week_rank\n",
    "billiboard['Peak Rank'] = Peak_rank\n",
    "billiboard['Weeks on board'] = Weeks_on_board\n",
    "billiboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2949148",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3dfd12b5",
   "metadata": {},
   "source": [
    "6. Scrape the details of Highest selling novels.   \n",
    "A) Book name   \n",
    "B) Author name   \n",
    "C) Volumes sold   \n",
    "D) Publisher   \n",
    "E) Genre   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "178f7ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# connecting to the webdrive\n",
    "driver=webdriver.Chrome()\n",
    "driver.get(\"http://www.google.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "4d0406ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get url in web driver first\n",
    "url = 'https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey-compare/'\n",
    "driver.get(url)\n",
    "#the url will open"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "194842f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating empty lists\n",
    "Book_name = []\n",
    "Author_name = []\n",
    "Volumes_sold = []\n",
    "Publisher = []\n",
    "Genre = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "6fc55378",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraping book names data\n",
    "for i in driver.find_elements(By.XPATH,\"//tbody//tr//td[2]\"):\n",
    "    Book_name.append(i.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "e95556dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraping author names data\n",
    "for i in driver.find_elements(By.XPATH,\"//tbody//tr//td[3]\"):\n",
    "    try:\n",
    "        if i.text == '0' : raise NoSuchElementException\n",
    "        Author_name.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        Author_name.append('-')\n",
    "time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "0ac9ce9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraping data of volumes sold\n",
    "for i in driver.find_elements(By.XPATH,\"//tbody//tr//td[4]\"):\n",
    "    Volumes_sold.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "ac9c1b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraping data of publisher names\n",
    "for i in driver.find_elements(By.XPATH,\"//tbody//tr//td[5]\"):\n",
    "    Publisher.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "ed0b315f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraping  data of genre\n",
    "for i in driver.find_elements(By.XPATH,\"//tbody//tr//td[6]\"):\n",
    "    Genre.append(i.text)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "d2980353",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Book Name</th>\n",
       "      <th>Author</th>\n",
       "      <th>Volume sold</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>Genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Da Vinci Code,The</td>\n",
       "      <td>Brown, Dan</td>\n",
       "      <td>5,094,805</td>\n",
       "      <td>Transworld</td>\n",
       "      <td>Crime, Thriller &amp; Adventure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Harry Potter and the Deathly Hallows</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,475,152</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Harry Potter and the Philosopher's Stone</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,200,654</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Harry Potter and the Order of the Phoenix</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,179,479</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fifty Shades of Grey</td>\n",
       "      <td>James, E. L.</td>\n",
       "      <td>3,758,936</td>\n",
       "      <td>Random House</td>\n",
       "      <td>Romance &amp; Sagas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Ghost,The</td>\n",
       "      <td>Harris, Robert</td>\n",
       "      <td>807,311</td>\n",
       "      <td>Random House</td>\n",
       "      <td>General &amp; Literary Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Happy Days with the Naked Chef</td>\n",
       "      <td>Oliver, Jamie</td>\n",
       "      <td>794,201</td>\n",
       "      <td>Penguin</td>\n",
       "      <td>Food &amp; Drink: General</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Hunger Games,The:Hunger Games Trilogy</td>\n",
       "      <td>Collins, Suzanne</td>\n",
       "      <td>792,187</td>\n",
       "      <td>Scholastic Ltd.</td>\n",
       "      <td>Young Adult Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Lost Boy,The:A Foster Child's Search for the L...</td>\n",
       "      <td>Pelzer, Dave</td>\n",
       "      <td>791,507</td>\n",
       "      <td>Orion</td>\n",
       "      <td>Biography: General</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Jamie's Ministry of Food:Anyone Can Learn to C...</td>\n",
       "      <td>Oliver, Jamie</td>\n",
       "      <td>791,095</td>\n",
       "      <td>Penguin</td>\n",
       "      <td>Food &amp; Drink: General</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows √ó 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Book Name            Author  \\\n",
       "0                                   Da Vinci Code,The        Brown, Dan   \n",
       "1                Harry Potter and the Deathly Hallows     Rowling, J.K.   \n",
       "2            Harry Potter and the Philosopher's Stone     Rowling, J.K.   \n",
       "3           Harry Potter and the Order of the Phoenix     Rowling, J.K.   \n",
       "4                                Fifty Shades of Grey      James, E. L.   \n",
       "..                                                ...               ...   \n",
       "95                                          Ghost,The    Harris, Robert   \n",
       "96                     Happy Days with the Naked Chef     Oliver, Jamie   \n",
       "97              Hunger Games,The:Hunger Games Trilogy  Collins, Suzanne   \n",
       "98  Lost Boy,The:A Foster Child's Search for the L...      Pelzer, Dave   \n",
       "99  Jamie's Ministry of Food:Anyone Can Learn to C...     Oliver, Jamie   \n",
       "\n",
       "   Volume sold        Publisher                        Genre  \n",
       "0    5,094,805       Transworld  Crime, Thriller & Adventure  \n",
       "1    4,475,152       Bloomsbury           Children's Fiction  \n",
       "2    4,200,654       Bloomsbury           Children's Fiction  \n",
       "3    4,179,479       Bloomsbury           Children's Fiction  \n",
       "4    3,758,936     Random House              Romance & Sagas  \n",
       "..         ...              ...                          ...  \n",
       "95     807,311     Random House   General & Literary Fiction  \n",
       "96     794,201          Penguin        Food & Drink: General  \n",
       "97     792,187  Scholastic Ltd.          Young Adult Fiction  \n",
       "98     791,507            Orion           Biography: General  \n",
       "99     791,095          Penguin        Food & Drink: General  \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating dataframe for scraped data\n",
    "Novels = pd.DataFrame({})\n",
    "Novels['Book Name'] = Book_name\n",
    "Novels['Author'] = Author_name\n",
    "Novels['Volume sold'] = Volumes_sold\n",
    "Novels['Publisher'] = Publisher\n",
    "Novels['Genre'] = Genre\n",
    "Novels "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16195055",
   "metadata": {},
   "source": [
    "7. Scrape the details most watched tv series of all time from imdb.com.   \n",
    "Url = https://www.imdb.com/list/ls095964455/ You have \n",
    "to find the following details:   \n",
    "A) Name   \n",
    "B) Year span   \n",
    "C) Genre   \n",
    "D) Run time   \n",
    "E) Ratings   \n",
    "F) Votes  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "6b4be936",
   "metadata": {},
   "outputs": [],
   "source": [
    "# connecting to the webdrive\n",
    "driver=webdriver.Chrome()\n",
    "driver.get(\"http://www.google.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "a0dc884d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting the webpage of mentioned url\n",
    "url = (\"https://www.imdb.com/search/title/?title_type=tv_series&sort=num_votes,desc\")\n",
    "driver.get(url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "7e1158d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating empty lists\n",
    "Name = []\n",
    "Year_span = []\n",
    "Genre = []\n",
    "Run_time = []\n",
    "Ratings = []\n",
    "Votes = []\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "6cdca0d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraped data of Names\n",
    "for i in driver.find_elements(By.XPATH,'//a[@class=\"ipc-title-link-wrapper\"]'):\n",
    "    Name.append(i.text)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "92633032",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraped data of Year span\n",
    "for i in driver.find_elements(By.XPATH,'//div[@class=\"sc-be6f1408-7 iUtHEN dli-title-metadata\"]'):\n",
    "    Year_span.append(i.text)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "acab028d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraped data of Ratings\n",
    "for i in driver.find_elements(By.XPATH,'//span[@class=\"ipc-rating-star ipc-rating-star--base ipc-rating-star--imdb ratingGroup--imdb-rating\"]'):\n",
    "    Ratings.append(i.text)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "9b0d2a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraped data of Votes\n",
    "for i in driver.find_elements(By.XPATH,'//div[@class=\"ipc-html-content ipc-html-content--base sc-f24f1c5c-1 KgkxE dli-plot-container\"]'):\n",
    "    Votes.append(i.text) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "4d53079a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Year Span</th>\n",
       "      <th>Ratings</th>\n",
       "      <th>Votes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1. Game of Thrones</td>\n",
       "      <td>2011‚Äì2019\\nTV-MA</td>\n",
       "      <td>9.2\\n (2.3M)</td>\n",
       "      <td>Nine noble families fight for control over the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2. Breaking Bad</td>\n",
       "      <td>2008‚Äì2013\\nTV-MA</td>\n",
       "      <td>9.5\\n (2.1M)</td>\n",
       "      <td>A chemistry teacher diagnosed with inoperable ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3. Stranger Things</td>\n",
       "      <td>2016‚Äì2025\\nTV-14</td>\n",
       "      <td>8.7\\n (1.3M)</td>\n",
       "      <td>When a young boy vanishes, a small town uncove...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4. Friends</td>\n",
       "      <td>1994‚Äì2004\\nTV-14</td>\n",
       "      <td>8.9\\n (1.1M)</td>\n",
       "      <td>Follows the personal and professional lives of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5. The Walking Dead</td>\n",
       "      <td>2010‚Äì2022\\nTV-MA</td>\n",
       "      <td>8.1\\n (1.1M)</td>\n",
       "      <td>Sheriff Deputy Rick Grimes wakes up from a com...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6. Sherlock</td>\n",
       "      <td>2010‚Äì2017\\nTV-14</td>\n",
       "      <td>9.1\\n (989K)</td>\n",
       "      <td>The quirky spin on Conan Doyle's iconic sleuth...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7. The Big Bang Theory</td>\n",
       "      <td>2007‚Äì2019\\nTV-PG</td>\n",
       "      <td>8.1\\n (860K)</td>\n",
       "      <td>A woman who moves into an apartment across the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8. Dexter</td>\n",
       "      <td>2006‚Äì2013\\nTV-MA</td>\n",
       "      <td>8.7\\n (759K)</td>\n",
       "      <td>He's smart. He's lovable. He's Dexter Morgan, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9. How I Met Your Mother</td>\n",
       "      <td>2005‚Äì2014\\nTV-14</td>\n",
       "      <td>8.3\\n (723K)</td>\n",
       "      <td>A father recounts to his children - through a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10. The Office</td>\n",
       "      <td>2005‚Äì2013\\nTV-14</td>\n",
       "      <td>9.0\\n (699K)</td>\n",
       "      <td>A mockumentary on a group of typical office wo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11. True Detective</td>\n",
       "      <td>2014‚Äì\\nTV-MA</td>\n",
       "      <td>8.9\\n (642K)</td>\n",
       "      <td>Anthology series in which police investigation...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12. Peaky Blinders</td>\n",
       "      <td>2013‚Äì2022\\nTV-MA</td>\n",
       "      <td>8.8\\n (637K)</td>\n",
       "      <td>A gangster family epic set in 1900s England, c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13. Better Call Saul</td>\n",
       "      <td>2015‚Äì2022\\nTV-MA</td>\n",
       "      <td>9.0\\n (636K)</td>\n",
       "      <td>The trials and tribulations of criminal lawyer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14. The Boys</td>\n",
       "      <td>2019‚Äì\\nTV-MA</td>\n",
       "      <td>8.7\\n (634K)</td>\n",
       "      <td>A group of vigilantes set out to take down cor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15. Black Mirror</td>\n",
       "      <td>2011‚Äì\\nTV-MA</td>\n",
       "      <td>8.7\\n (632K)</td>\n",
       "      <td>Featuring stand-alone dramas -- sharp, suspens...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16. Rick and Morty</td>\n",
       "      <td>2013‚Äì\\nTV-MA</td>\n",
       "      <td>9.1\\n (594K)</td>\n",
       "      <td>The fractured domestic lives of a nihilistic m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17. Lost</td>\n",
       "      <td>2004‚Äì2010\\nTV-14</td>\n",
       "      <td>8.3\\n (590K)</td>\n",
       "      <td>The survivors of a plane crash are forced to w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18. The Mandalorian</td>\n",
       "      <td>2019‚Äì\\nTV-14</td>\n",
       "      <td>8.7\\n (580K)</td>\n",
       "      <td>The travels of a lone bounty hunter in the out...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19. Vikings</td>\n",
       "      <td>2013‚Äì2020\\nTV-MA</td>\n",
       "      <td>8.5\\n (575K)</td>\n",
       "      <td>Vikings transports us to the brutal and myster...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20. Prison Break</td>\n",
       "      <td>2005‚Äì2017\\nTV-14</td>\n",
       "      <td>8.3\\n (574K)</td>\n",
       "      <td>A structural engineer installs himself in a pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21. The Witcher</td>\n",
       "      <td>2019‚Äì\\nTV-MA</td>\n",
       "      <td>8.0\\n (565K)</td>\n",
       "      <td>Geralt of Rivia, a solitary monster hunter, st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22. Squid Game</td>\n",
       "      <td>2021‚Äì\\nTV-MA</td>\n",
       "      <td>8.0\\n (531K)</td>\n",
       "      <td>Hundreds of cash-strapped players accept a str...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23. Westworld</td>\n",
       "      <td>2016‚Äì2022\\nTV-MA</td>\n",
       "      <td>8.5\\n (529K)</td>\n",
       "      <td>At the intersection of the near future and the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24. House of Cards</td>\n",
       "      <td>2013‚Äì2018\\nTV-MA</td>\n",
       "      <td>8.6\\n (528K)</td>\n",
       "      <td>A Congressman works with his equally conniving...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25. Money Heist</td>\n",
       "      <td>2017‚Äì2021\\nTV-MA</td>\n",
       "      <td>8.2\\n (526K)</td>\n",
       "      <td>An unusual group of robbers attempt to carry o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26. House</td>\n",
       "      <td>2004‚Äì2012\\nTV-14</td>\n",
       "      <td>8.7\\n (504K)</td>\n",
       "      <td>Using a crack team of doctors and his wits, an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27. The Last of Us</td>\n",
       "      <td>2023‚Äì\\nTV-MA</td>\n",
       "      <td>8.8\\n (501K)</td>\n",
       "      <td>After a global pandemic destroys civilization,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28. Attack on Titan</td>\n",
       "      <td>2013‚Äì2023\\nTV-MA</td>\n",
       "      <td>9.1\\n (498K)</td>\n",
       "      <td>After his hometown is destroyed and is traumat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29. Supernatural</td>\n",
       "      <td>2005‚Äì2020\\nTV-14</td>\n",
       "      <td>8.4\\n (479K)</td>\n",
       "      <td>Two brothers follow their father's footsteps a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30. Modern Family</td>\n",
       "      <td>2009‚Äì2020\\nTV-PG</td>\n",
       "      <td>8.5\\n (477K)</td>\n",
       "      <td>Three different, but related, families face tr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>31. Suits</td>\n",
       "      <td>2011‚Äì2019\\nTV-14</td>\n",
       "      <td>8.4\\n (471K)</td>\n",
       "      <td>On the run from a drug deal gone bad, brillian...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>32. Daredevil</td>\n",
       "      <td>2015‚Äì2018\\nTV-MA</td>\n",
       "      <td>8.6\\n (471K)</td>\n",
       "      <td>A blind lawyer by day, vigilante by night. Mat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>33. Narcos</td>\n",
       "      <td>2015‚Äì2017\\nTV-MA</td>\n",
       "      <td>8.8\\n (465K)</td>\n",
       "      <td>A chronicled look at the criminal exploits of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>34. The Sopranos</td>\n",
       "      <td>1999‚Äì2007\\nTV-MA</td>\n",
       "      <td>9.2\\n (462K)</td>\n",
       "      <td>New Jersey mob boss Tony Soprano deals with pe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>35. Arrow</td>\n",
       "      <td>2012‚Äì2020\\nTV-14</td>\n",
       "      <td>7.5\\n (445K)</td>\n",
       "      <td>Spoiled billionaire playboy Oliver Queen is mi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>36. Dark</td>\n",
       "      <td>2017‚Äì2020\\nTV-MA</td>\n",
       "      <td>8.7\\n (437K)</td>\n",
       "      <td>A family saga with a supernatural twist, set i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>37. The Simpsons</td>\n",
       "      <td>1989‚Äì\\nTV-14</td>\n",
       "      <td>8.7\\n (433K)</td>\n",
       "      <td>The satiric adventures of a working-class fami...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>38. Fargo</td>\n",
       "      <td>2014‚Äì2024\\nTV-MA</td>\n",
       "      <td>8.9\\n (416K)</td>\n",
       "      <td>Various chronicles of deception, intrigue, and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>39. Mr. Robot</td>\n",
       "      <td>2015‚Äì2019\\nTV-MA</td>\n",
       "      <td>8.5\\n (415K)</td>\n",
       "      <td>Elliot, a brilliant but unstable cyber-securit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>40. Loki</td>\n",
       "      <td>2021‚Äì2023\\nTV-14</td>\n",
       "      <td>8.2\\n (406K)</td>\n",
       "      <td>The mercurial villain Loki resumes his role as...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>41. South Park</td>\n",
       "      <td>1997‚Äì\\nTV-MA</td>\n",
       "      <td>8.7\\n (403K)</td>\n",
       "      <td>Follows the misadventures of four irreverent g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>42. The Wire</td>\n",
       "      <td>2002‚Äì2008\\nTV-MA</td>\n",
       "      <td>9.3\\n (373K)</td>\n",
       "      <td>The Baltimore drug scene, as seen through the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>43. Death Note</td>\n",
       "      <td>2006‚Äì2007\\nTV-14</td>\n",
       "      <td>8.9\\n (372K)</td>\n",
       "      <td>An intelligent high school student goes on a s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>44. The Flash</td>\n",
       "      <td>2014‚Äì2023\\nTV-PG</td>\n",
       "      <td>7.5\\n (367K)</td>\n",
       "      <td>After being struck by lightning, Barry Allen w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>45. House of the Dragon</td>\n",
       "      <td>2022‚Äì\\nTV-MA</td>\n",
       "      <td>8.4\\n (363K)</td>\n",
       "      <td>An internal succession war within House Targar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>46. Family Guy</td>\n",
       "      <td>1999‚Äì2025\\nTV-MA</td>\n",
       "      <td>8.2\\n (362K)</td>\n",
       "      <td>In a wacky Rhode Island town, a dysfunctional ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>47. Homeland</td>\n",
       "      <td>2011‚Äì2020\\nTV-MA</td>\n",
       "      <td>8.3\\n (359K)</td>\n",
       "      <td>A bipolar CIA operative becomes convinced a pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>48. Avatar: The Last Airbender</td>\n",
       "      <td>2005‚Äì2008\\nTV-Y7-FV</td>\n",
       "      <td>9.3\\n (358K)</td>\n",
       "      <td>In a war-torn world of elemental magic, a youn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>49. Brooklyn Nine-Nine</td>\n",
       "      <td>2013‚Äì2021\\nTV-14</td>\n",
       "      <td>8.4\\n (356K)</td>\n",
       "      <td>Comedy series following the exploits of Det. J...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>50. Wednesday</td>\n",
       "      <td>2022‚Äì\\nTV-14</td>\n",
       "      <td>8.1\\n (353K)</td>\n",
       "      <td>Follows Wednesday Addams' years as a student, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Name            Year Span       Ratings  \\\n",
       "0               1. Game of Thrones     2011‚Äì2019\\nTV-MA  9.2\\n (2.3M)   \n",
       "1                  2. Breaking Bad     2008‚Äì2013\\nTV-MA  9.5\\n (2.1M)   \n",
       "2               3. Stranger Things     2016‚Äì2025\\nTV-14  8.7\\n (1.3M)   \n",
       "3                       4. Friends     1994‚Äì2004\\nTV-14  8.9\\n (1.1M)   \n",
       "4              5. The Walking Dead     2010‚Äì2022\\nTV-MA  8.1\\n (1.1M)   \n",
       "5                      6. Sherlock     2010‚Äì2017\\nTV-14  9.1\\n (989K)   \n",
       "6           7. The Big Bang Theory     2007‚Äì2019\\nTV-PG  8.1\\n (860K)   \n",
       "7                        8. Dexter     2006‚Äì2013\\nTV-MA  8.7\\n (759K)   \n",
       "8         9. How I Met Your Mother     2005‚Äì2014\\nTV-14  8.3\\n (723K)   \n",
       "9                   10. The Office     2005‚Äì2013\\nTV-14  9.0\\n (699K)   \n",
       "10              11. True Detective         2014‚Äì\\nTV-MA  8.9\\n (642K)   \n",
       "11              12. Peaky Blinders     2013‚Äì2022\\nTV-MA  8.8\\n (637K)   \n",
       "12            13. Better Call Saul     2015‚Äì2022\\nTV-MA  9.0\\n (636K)   \n",
       "13                    14. The Boys         2019‚Äì\\nTV-MA  8.7\\n (634K)   \n",
       "14                15. Black Mirror         2011‚Äì\\nTV-MA  8.7\\n (632K)   \n",
       "15              16. Rick and Morty         2013‚Äì\\nTV-MA  9.1\\n (594K)   \n",
       "16                        17. Lost     2004‚Äì2010\\nTV-14  8.3\\n (590K)   \n",
       "17             18. The Mandalorian         2019‚Äì\\nTV-14  8.7\\n (580K)   \n",
       "18                     19. Vikings     2013‚Äì2020\\nTV-MA  8.5\\n (575K)   \n",
       "19                20. Prison Break     2005‚Äì2017\\nTV-14  8.3\\n (574K)   \n",
       "20                 21. The Witcher         2019‚Äì\\nTV-MA  8.0\\n (565K)   \n",
       "21                  22. Squid Game         2021‚Äì\\nTV-MA  8.0\\n (531K)   \n",
       "22                   23. Westworld     2016‚Äì2022\\nTV-MA  8.5\\n (529K)   \n",
       "23              24. House of Cards     2013‚Äì2018\\nTV-MA  8.6\\n (528K)   \n",
       "24                 25. Money Heist     2017‚Äì2021\\nTV-MA  8.2\\n (526K)   \n",
       "25                       26. House     2004‚Äì2012\\nTV-14  8.7\\n (504K)   \n",
       "26              27. The Last of Us         2023‚Äì\\nTV-MA  8.8\\n (501K)   \n",
       "27             28. Attack on Titan     2013‚Äì2023\\nTV-MA  9.1\\n (498K)   \n",
       "28                29. Supernatural     2005‚Äì2020\\nTV-14  8.4\\n (479K)   \n",
       "29               30. Modern Family     2009‚Äì2020\\nTV-PG  8.5\\n (477K)   \n",
       "30                       31. Suits     2011‚Äì2019\\nTV-14  8.4\\n (471K)   \n",
       "31                   32. Daredevil     2015‚Äì2018\\nTV-MA  8.6\\n (471K)   \n",
       "32                      33. Narcos     2015‚Äì2017\\nTV-MA  8.8\\n (465K)   \n",
       "33                34. The Sopranos     1999‚Äì2007\\nTV-MA  9.2\\n (462K)   \n",
       "34                       35. Arrow     2012‚Äì2020\\nTV-14  7.5\\n (445K)   \n",
       "35                        36. Dark     2017‚Äì2020\\nTV-MA  8.7\\n (437K)   \n",
       "36                37. The Simpsons         1989‚Äì\\nTV-14  8.7\\n (433K)   \n",
       "37                       38. Fargo     2014‚Äì2024\\nTV-MA  8.9\\n (416K)   \n",
       "38                   39. Mr. Robot     2015‚Äì2019\\nTV-MA  8.5\\n (415K)   \n",
       "39                        40. Loki     2021‚Äì2023\\nTV-14  8.2\\n (406K)   \n",
       "40                  41. South Park         1997‚Äì\\nTV-MA  8.7\\n (403K)   \n",
       "41                    42. The Wire     2002‚Äì2008\\nTV-MA  9.3\\n (373K)   \n",
       "42                  43. Death Note     2006‚Äì2007\\nTV-14  8.9\\n (372K)   \n",
       "43                   44. The Flash     2014‚Äì2023\\nTV-PG  7.5\\n (367K)   \n",
       "44         45. House of the Dragon         2022‚Äì\\nTV-MA  8.4\\n (363K)   \n",
       "45                  46. Family Guy     1999‚Äì2025\\nTV-MA  8.2\\n (362K)   \n",
       "46                    47. Homeland     2011‚Äì2020\\nTV-MA  8.3\\n (359K)   \n",
       "47  48. Avatar: The Last Airbender  2005‚Äì2008\\nTV-Y7-FV  9.3\\n (358K)   \n",
       "48          49. Brooklyn Nine-Nine     2013‚Äì2021\\nTV-14  8.4\\n (356K)   \n",
       "49                   50. Wednesday         2022‚Äì\\nTV-14  8.1\\n (353K)   \n",
       "\n",
       "                                                Votes  \n",
       "0   Nine noble families fight for control over the...  \n",
       "1   A chemistry teacher diagnosed with inoperable ...  \n",
       "2   When a young boy vanishes, a small town uncove...  \n",
       "3   Follows the personal and professional lives of...  \n",
       "4   Sheriff Deputy Rick Grimes wakes up from a com...  \n",
       "5   The quirky spin on Conan Doyle's iconic sleuth...  \n",
       "6   A woman who moves into an apartment across the...  \n",
       "7   He's smart. He's lovable. He's Dexter Morgan, ...  \n",
       "8   A father recounts to his children - through a ...  \n",
       "9   A mockumentary on a group of typical office wo...  \n",
       "10  Anthology series in which police investigation...  \n",
       "11  A gangster family epic set in 1900s England, c...  \n",
       "12  The trials and tribulations of criminal lawyer...  \n",
       "13  A group of vigilantes set out to take down cor...  \n",
       "14  Featuring stand-alone dramas -- sharp, suspens...  \n",
       "15  The fractured domestic lives of a nihilistic m...  \n",
       "16  The survivors of a plane crash are forced to w...  \n",
       "17  The travels of a lone bounty hunter in the out...  \n",
       "18  Vikings transports us to the brutal and myster...  \n",
       "19  A structural engineer installs himself in a pr...  \n",
       "20  Geralt of Rivia, a solitary monster hunter, st...  \n",
       "21  Hundreds of cash-strapped players accept a str...  \n",
       "22  At the intersection of the near future and the...  \n",
       "23  A Congressman works with his equally conniving...  \n",
       "24  An unusual group of robbers attempt to carry o...  \n",
       "25  Using a crack team of doctors and his wits, an...  \n",
       "26  After a global pandemic destroys civilization,...  \n",
       "27  After his hometown is destroyed and is traumat...  \n",
       "28  Two brothers follow their father's footsteps a...  \n",
       "29  Three different, but related, families face tr...  \n",
       "30  On the run from a drug deal gone bad, brillian...  \n",
       "31  A blind lawyer by day, vigilante by night. Mat...  \n",
       "32  A chronicled look at the criminal exploits of ...  \n",
       "33  New Jersey mob boss Tony Soprano deals with pe...  \n",
       "34  Spoiled billionaire playboy Oliver Queen is mi...  \n",
       "35  A family saga with a supernatural twist, set i...  \n",
       "36  The satiric adventures of a working-class fami...  \n",
       "37  Various chronicles of deception, intrigue, and...  \n",
       "38  Elliot, a brilliant but unstable cyber-securit...  \n",
       "39  The mercurial villain Loki resumes his role as...  \n",
       "40  Follows the misadventures of four irreverent g...  \n",
       "41  The Baltimore drug scene, as seen through the ...  \n",
       "42  An intelligent high school student goes on a s...  \n",
       "43  After being struck by lightning, Barry Allen w...  \n",
       "44  An internal succession war within House Targar...  \n",
       "45  In a wacky Rhode Island town, a dysfunctional ...  \n",
       "46  A bipolar CIA operative becomes convinced a pr...  \n",
       "47  In a war-torn world of elemental magic, a youn...  \n",
       "48  Comedy series following the exploits of Det. J...  \n",
       "49  Follows Wednesday Addams' years as a student, ...  "
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating dataframe for scraped data\n",
    "TV_Series = pd.DataFrame({})\n",
    "TV_Series['Name'] = Name\n",
    "TV_Series['Year Span'] = Year_span\n",
    "TV_Series['Ratings'] = Ratings\n",
    "TV_Series['Votes'] = Votes\n",
    "TV_Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "1c100f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "898efddf",
   "metadata": {},
   "source": [
    "Details of Datasets from UCI machine learning repositories.   \n",
    "Url = https://archive.ics.uci.edu/  You \n",
    "have to find the following details:   \n",
    "A) Dataset name   \n",
    "B) Data type   \n",
    "C) Task   \n",
    "D) Attribute type   \n",
    "E) No of instances   \n",
    "F) No of attribute G) Year  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "6f782c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# connecting to the webdrive\n",
    "driver=webdriver.Chrome()\n",
    "driver.get(\"http://www.google.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "dfd7d7a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting the webpage of mentioned url\n",
    "url = (\" https://archive.ics.uci.edu/\")\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "091e8013",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fetching view all dataset button from the webpage\n",
    "viewall_dataset = driver.find_element(By.XPATH,'//a[@class=\"btn-primary btn\"]')\n",
    "page_url = viewall_dataset.get_attribute(\"href\")\n",
    "driver.get(page_url)\n",
    "time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "d2f28805",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating empty lists\n",
    "Dataset_name = []\n",
    "Data_type = []\n",
    "Task = []\n",
    "Attribute_type = []\n",
    "No_of_instances = []\n",
    "No_of_attributes = []\n",
    "Year = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "42640f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract the tag having dataset Name\n",
    "name =driver.find_elements(By.XPATH,'//a[@class=\"link-hover link text-xl font-semibold\"]')\n",
    "#to remove extra data other than output we required\n",
    "Dataset_Name=[]\n",
    "for i in name:\n",
    "    Dataset_Name.append(i.text)\n",
    "Dataset_name = []\n",
    "for i in Dataset_Name[44: :2]:\n",
    "    Dataset_name.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "61ea693d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract the tag having dataset Name\n",
    "datatype =driver.find_elements(By.XPATH,'//span[@class=\"truncate\"]')\n",
    "#to remove extra data other than output we required\n",
    "Data_type=[]\n",
    "for i in datat:\n",
    "    Data_type.append(i.text)\n",
    "\n",
    "Data_Type=[]\n",
    "for i in Data_type[25: :7]:\n",
    "    Data_Type.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "7a105274",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract the tag having dataset Name\n",
    "task =driver.find_elements(By.XPATH,'//div[@class=\"col-span-3 flex items-center gap-2\"]')\n",
    "#to remove extra data other than output we required\n",
    "Task=[]\n",
    "for i in task:\n",
    "    Task.append(i.text)\n",
    "\n",
    "TASK=[]\n",
    "for i in Task[26: :7]:\n",
    "    TASK.append(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "6e31d16e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Attribute_Type=[]\n",
    "for i in Data_type[27: :7]:\n",
    "    Attribute_Type.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "abcb22aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "Instances = []\n",
    "for i in Data_type[28: :7]:\n",
    "    Instances.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "2634082f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Attribute=[]\n",
    "for i in Data_type[29: :7]:\n",
    "    Attribute.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "d7d9af64",
   "metadata": {},
   "outputs": [],
   "source": [
    "Year=[]\n",
    "for i in Data_type[30: :7]:\n",
    "    Year.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "id": "8ab94640",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Length of values (0) does not match length of index (3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[303], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m ML_REPOSITORIES[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDataset_name\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m=\u001b[39m Dataset_name\n\u001b[0;32m      4\u001b[0m ML_REPOSITORIES[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mData_Type\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m Data_Type\n\u001b[1;32m----> 5\u001b[0m ML_REPOSITORIES[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTask\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m TASK \n\u001b[0;32m      6\u001b[0m ML_REPOSITORIES[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAttribute_Type\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m Attribute_Type\n\u001b[0;32m      7\u001b[0m ML_REPOSITORIES[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInstances\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m Instances \n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:3950\u001b[0m, in \u001b[0;36mDataFrame.__setitem__\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   3947\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_setitem_array([key], value)\n\u001b[0;32m   3948\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   3949\u001b[0m     \u001b[38;5;66;03m# set column\u001b[39;00m\n\u001b[1;32m-> 3950\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_item(key, value)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:4143\u001b[0m, in \u001b[0;36mDataFrame._set_item\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   4133\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_set_item\u001b[39m(\u001b[38;5;28mself\u001b[39m, key, value) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   4134\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   4135\u001b[0m \u001b[38;5;124;03m    Add series to DataFrame in specified column.\u001b[39;00m\n\u001b[0;32m   4136\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4141\u001b[0m \u001b[38;5;124;03m    ensure homogeneity.\u001b[39;00m\n\u001b[0;32m   4142\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 4143\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sanitize_column(value)\n\u001b[0;32m   4145\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m   4146\u001b[0m         key \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\n\u001b[0;32m   4147\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m value\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   4148\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_extension_array_dtype(value)\n\u001b[0;32m   4149\u001b[0m     ):\n\u001b[0;32m   4150\u001b[0m         \u001b[38;5;66;03m# broadcast across multiple columns if necessary\u001b[39;00m\n\u001b[0;32m   4151\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mis_unique \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns, MultiIndex):\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:4870\u001b[0m, in \u001b[0;36mDataFrame._sanitize_column\u001b[1;34m(self, value)\u001b[0m\n\u001b[0;32m   4867\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _reindex_for_setitem(Series(value), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex)\n\u001b[0;32m   4869\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_list_like(value):\n\u001b[1;32m-> 4870\u001b[0m     com\u001b[38;5;241m.\u001b[39mrequire_length_match(value, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex)\n\u001b[0;32m   4871\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m sanitize_array(value, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, allow_2d\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\common.py:576\u001b[0m, in \u001b[0;36mrequire_length_match\u001b[1;34m(data, index)\u001b[0m\n\u001b[0;32m    572\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    573\u001b[0m \u001b[38;5;124;03mCheck the length of data matches the length of the index.\u001b[39;00m\n\u001b[0;32m    574\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    575\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(data) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(index):\n\u001b[1;32m--> 576\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    577\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLength of values \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    578\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(data)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    579\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdoes not match length of index \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    580\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(index)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    581\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Length of values (0) does not match length of index (3)"
     ]
    }
   ],
   "source": [
    "# Make data frame of Datasets from UCI machine learning repositories from Url = https://archive.ics.uci.edu/\n",
    "ML_REPOSITORIES = pd.DataFrame({})\n",
    "ML_REPOSITORIES['Dataset_name']= Dataset_name\n",
    "ML_REPOSITORIES['Data_Type'] = Data_Type\n",
    "ML_REPOSITORIES['Task'] = TASK \n",
    "ML_REPOSITORIES['Attribute_Type'] = Attribute_Type\n",
    "ML_REPOSITORIES['Instances'] = Instances \n",
    "ML_REPOSITORIES['Attribute'] = Attribute \n",
    "ML_REPOSITORIES['Year'] = Year\n",
    "ML_REPOSITORIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3b2635d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d4129bb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
